---

# ------------------------------------------------------------------------------
# General Properties
# ------------------------------------------------------------------------------
id: "mongodb"
name: "MongoDB source database"
type: "tap-mongodb"
owner: "somebody@foo.com"
#send_alert: False                     # Optional: Disable all configured alerts on this tap


# ------------------------------------------------------------------------------
# Source (Tap) - Mongo connection details
# ------------------------------------------------------------------------------
db_conn:
  host: "<db host>"               					# Mongodb host, if multiple hosts, list the hosts separated by comma
  auth_database: "<authentication db name>"         # the Mongodb database name to authenticate on
  dbname: "<sync db name>"           				# Mongodb database name to sync from
  username: "<USERNAME>"							# User with read roles
  password: "<PASSWORD>"                            # Plain string or vault encrypted
  password: "secret"                    			# Mongodb plain string or vault encrypted
  replica_set: "<replicaSet name>"        			# Optional: Mongodb replica set name, default null
  write_batch_rows: <int>							# Optional: Number of rows to write to csv file
                                       				#           in one batch. Default is 50000.

  update_buffer_size: <int> 						# Optional: [LOG_BASED] The size of the buffer that holds detected update
  													# operations in memory, the buffer is flushed once the size is reached. Default is 1.
  await_time_ms: <int>								# Optional: [LOG_BASED] The maximum amount of time in milliseconds
  													# the loge_base method waits for new data changes before exiting. Default is 1000 ms.
  fastsync_parallelism: <int>                       # Optional: size of multiprocessing pool used by FastSync
                                                    #           Min: 1
                                                    #           Default: number of CPU cores

# ------------------------------------------------------------------------------
# Destination (Target) - Target properties
# Connection details should be in the relevant target YAML file
# ------------------------------------------------------------------------------
target: "snowflake"                   				# ID of the target connector where the data will be loaded
batch_size_rows: 1000                  				# Batch size for the stream to optimise load performance
stream_buffer_size: 0                               # In-memory buffer size (MB) between taps and targets for asynchronous data pipes
default_target_schema: "<sync db name>"             # Optional: Default target schema where the data will be loaded
#default_target_schema_select_permission:  			# Optional: Grant SELECT on schema and tables that created
#  - grp_power
#batch_wait_limit_seconds: 3600                     # Optional: Maximum time to wait for `batch_size_rows`. Available only for snowflake target.

# Options only for Snowflake target
#split_large_files: False                       # Optional: split large files to multiple pieces and create multipart zip files. (Default: False)
#split_file_chunk_size_mb: 1000                 # Optional: File chunk sizes if `split_large_files` enabled. (Default: 1000)
#split_file_max_chunks: 20                      # Optional: Max number of chunks if `split_large_files` enabled. (Default: 20)
#archive_load_files: False                      # Optional: when enabled, the files loaded to Snowflake will also be stored in `archive_load_files_s3_bucket`
#archive_load_files_s3_prefix: "archive"        # Optional: When `archive_load_files` is enabled, the archived files will be placed in the archive S3 bucket under this prefix.
#archive_load_files_s3_bucket: "<BUCKET_NAME>"  # Optional: When `archive_load_files` is enabled, the archived files will be placed in this bucket. (Default: the value of `s3_bucket` in target snowflake YAML)


# ------------------------------------------------------------------------------
# Source to target Schema mapping
# ------------------------------------------------------------------------------
schemas:
  - source_schema: "<dbname>"    				# Must be same name as dbname
    target_schema: "<target schema name>"     	# schema where the data will be loaded
    target_schema_select_permissions:  			# Optional: Grant SELECT on schema and tables that created
      - grp_stats

 	# Available replication methods: FULL_TABLE & LOG_BASED
    # Default replication method is LOG_BASED
    tables:
      - table_name: "table1"
        replication_method: "FULL_TABLE"

		# OPTIONAL: Load time transformations
        #transformations:
        #  - column: "last_name"            # Column to transform
        #    type: "SET-NULL"               # Transformation type

 	  - table_name: "table2"
