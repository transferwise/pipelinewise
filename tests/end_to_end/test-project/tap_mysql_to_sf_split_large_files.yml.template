---

# ------------------------------------------------------------------------------
# General Properties
# ------------------------------------------------------------------------------
id: "mariadb_to_sf_split_large_files"
name: "MariaDB source test database"
type: "tap-mysql"
owner: "test-runner"


# ------------------------------------------------------------------------------
# Source (Tap) - MySQL connection details
# ------------------------------------------------------------------------------
db_conn:
  host: "${TAP_MYSQL_HOST}"             # MySQL host
  port: ${TAP_MYSQL_PORT}               # MySQL port
  user: "${TAP_MYSQL_USER}"             # MySQL user
  password: "${TAP_MYSQL_PASSWORD}"     # Plain string or vault encrypted
  dbname: "${TAP_MYSQL_DB}"             # MySQL database name


# ------------------------------------------------------------------------------
# Destination (Target) - Target properties
# Connection details should be in the relevant target YAML file
# ------------------------------------------------------------------------------
target: "snowflake"                    # ID of the target connector where the data will be loaded
batch_size_rows: 20000                 # Batch size for the stream to optimise load performance
stream_buffer_size: 0                  # In-memory buffer size (MB) between taps and targets for asynchronous data pipes

# Enable splitting large files to smaller pieces
split_large_files: True
split_file_chunk_size_mb: 1
split_file_max_chunks: 5


# ------------------------------------------------------------------------------
# Source to target Schema mapping
# ------------------------------------------------------------------------------
schemas:
  - source_schema: "mysql_source_db"
    target_schema: "ppw_e2e_tap_mysql${TARGET_SNOWFLAKE_SCHEMA_POSTFIX}"

    tables:
      - table_name: "address"
