---

# ------------------------------------------------------------------------------
# General Properties
# ------------------------------------------------------------------------------
id: "postgres_to_sf_split_large_files"
name: "PostgreSQL source test database"
type: "tap-postgres"
owner: "test-runner"


# ------------------------------------------------------------------------------
# Source (Tap) - PostgreSQL connection details
# ------------------------------------------------------------------------------
db_conn:
  host: "${TAP_POSTGRES_HOST}"          # PostgreSQL host
  logical_poll_total_seconds: 3         # Time out if no LOG_BASED changes received for 3 seconds
  port: ${TAP_POSTGRES_PORT}            # PostgreSQL port
  user: "${TAP_POSTGRES_USER}"          # PostgreSQL user
  password: "${TAP_POSTGRES_PASSWORD}"  # Plain string or vault encrypted
  dbname: "${TAP_POSTGRES_DB}"          # PostgreSQL database name


# ------------------------------------------------------------------------------
# Destination (Target) - Target properties
# Connection details should be in the relevant target YAML file
# ------------------------------------------------------------------------------
target: "snowflake"                    # ID of the target connector where the data will be loaded
batch_size_rows: 1000                  # Batch size for the stream to optimise load performance
stream_buffer_size: 0                  # In-memory buffer size (MB) between taps and targets for asynchronous data pipes

# Enable splitting large files to smaller pieces
split_large_files: True
split_file_chunk_size_mb: 1
split_file_max_chunks: 5


# ------------------------------------------------------------------------------
# Source to target Schema mapping
# ------------------------------------------------------------------------------
schemas:
  - source_schema: "public"
    target_schema: "ppw_e2e_tap_postgres"

    tables:
      - table_name: "city"
